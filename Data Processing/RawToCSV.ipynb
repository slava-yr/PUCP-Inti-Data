{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e94a16d",
   "metadata": {},
   "source": [
    "# Raw to CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ece0e",
   "metadata": {},
   "source": [
    "**Goal**: Process the raw CSV files from the I-V Curve Tracer to get 1 CSV file with only the relevant columns.\n",
    "\n",
    "**Output**: unfiltered_dataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88668907",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987d1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85d54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"../Raw_Data/\") # Base path for raw data files\n",
    "output_csv = Path(\"unfiltered_dataset.csv\") # Output CSV file path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9764f",
   "metadata": {},
   "source": [
    "## Localize all CSV files from 2023 to 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaf5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CSV files from 2023-2025\n",
    "all_files = []\n",
    "skip_prefixes = ('MS711', 'WS500', 'PV')\n",
    "\n",
    "for year in range(2022, 2026):  # 2022-2025\n",
    "    year_files = list(base_path.glob(f\"{year}/**/*.csv\"))\n",
    "    # Filter out unwanted prefixes\n",
    "    year_files = [f for f in year_files if not f.name.startswith(skip_prefixes)]\n",
    "    all_files.extend(year_files)\n",
    "    print(f\"Found {len(year_files)} files in {year}\")\n",
    "\n",
    "total_files = len(all_files)\n",
    "print(f\"\\nTotal: {total_files} CSV files from 2022-2025 (excluding MS711, WS500, PV)\")\n",
    "\n",
    "print(f\"Files to process: {total_files}\")\n",
    "\n",
    "# Determine if we need header\n",
    "write_header = not output_csv.exists() or output_csv.stat().st_size == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232335a5",
   "metadata": {},
   "source": [
    "## Column extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88ead9",
   "metadata": {},
   "source": [
    "Identified structure of raw CSV files. Some files have additional columns corresponding to diffuse irradiance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362b3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_row1_column_names = [\n",
    "    'date', 'time_start', 'voltage_0', 'current_0', 'power_0', 'wavelength_0', 'spectralirr_0',\n",
    "    'modtemp_c', 'modtemp_l', 'cell_v', 'irr_horiz_start', 'irr_incl20_start', 'airtemp',\n",
    "    'humidity_rel', 'pressure_rel', 'air_density', 'wind_speed_kmh',\n",
    "    'wind_dir', 'humidity_abs', 'pressure_abs', 'wind_speed_ms', 'irr_east_start',\n",
    "    'irr_west_start', 'irr_floor_ref_start'\n",
    "]\n",
    "\n",
    "full_row1_column_names = base_row1_column_names + ['irr_diffuse_start', 'irr_incl15_start']\n",
    "\n",
    "base_row2_column_names = [\n",
    "    'module_name', 'time_end', 'voltage_1', 'current_1',\n",
    "    'power_1', 'wavelength_1', 'spectralirr_1', 'cell_v_end',\n",
    "    'irr_horiz_end', 'irr_incl20_end', 'irr_east_end', 'irr_west_end',\n",
    "    'irr_floor_ref_end']\n",
    "\n",
    "full_row2_column_names = base_row2_column_names + ['irr_diffuse_end', 'irr_incl15_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5ad14",
   "metadata": {},
   "source": [
    "# Process file function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be1d8b",
   "metadata": {},
   "source": [
    "This function extracts all the needed data from the raw CSV files. It also computes other variables for the dataset based on the I-V curve and spectroradiometer measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d294772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    filename = file_path.name\n",
    "\n",
    "    ## Read CSV \n",
    "    opts = dict(sep=';', header=None, na_values='--', engine='python')\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='utf-8', encoding_errors='strict', **opts)\n",
    "    except UnicodeDecodeError:\n",
    "        # Fallback to latin1 if UTF-8 fails (handles the \\xe3 byte)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='latin1', encoding_errors='replace', **opts)\n",
    "        except Exception as e:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    # Check number of columns (26 or 24 expected)\n",
    "    num_cols = df.shape[1]\n",
    "    if num_cols == 26:\n",
    "        current_row1_names = full_row1_column_names\n",
    "        current_row2_names = full_row2_column_names\n",
    "    elif num_cols == 24:\n",
    "        current_row1_names = base_row1_column_names\n",
    "        current_row2_names = base_row2_column_names\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # Parse Row 1\n",
    "    try:\n",
    "        row1_list = df.iloc[0, :].dropna().tolist()\n",
    "        if len(row1_list) == len(current_row1_names):\n",
    "            df_row1 = pd.DataFrame([row1_list], columns=current_row1_names)\n",
    "        else: # Fallback\n",
    "            df_row1 = pd.DataFrame([df.iloc[0, :len(current_row1_names)].tolist()], columns=current_row1_names)\n",
    "        row1 = df_row1.iloc[0]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    # Parse Row 2\n",
    "    try:\n",
    "        row2_list = df.iloc[1, :].dropna().tolist()\n",
    "        if len(row2_list) == len(current_row2_names):\n",
    "            df_row2 = pd.DataFrame([row2_list], columns=current_row2_names)\n",
    "        else:\n",
    "            # Fallback for Row 2: Explicitly pull indices to handle the gaps\n",
    "            row2_idxs = [0, 1, 2, 3, 4, 5, 6, 7, 10, 11, 21, 22, 23]\n",
    "            if num_cols == 26:\n",
    "                row2_idxs += [24, 25] # Add Diffuse and GTI 15 for 26-col files\n",
    "            df_row2 = pd.DataFrame([df.iloc[1, row2_idxs].tolist()], columns=current_row2_names)\n",
    "        row2 = df_row2.iloc[0]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    ## Generate timestamp from filename\n",
    "    try:\n",
    "        name = filename.replace('.csv', '')\n",
    "        parts = name.split('_')\n",
    "        # Extract date/time parts\n",
    "        day = int(parts[1])\n",
    "        month = int(parts[2])\n",
    "        year = int(parts[3])\n",
    "        hour = int(parts[4])\n",
    "        minute = int(parts[5])\n",
    "        second_str = parts[6].split(' ')[0]\n",
    "        second = int(second_str)\n",
    "        \n",
    "        timestamp = datetime(year, month, day, hour, minute, second)\n",
    "        \n",
    "        module_name = row2[\"module_name\"]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    ## Spectral Integral (spectroradiometer measurements)\n",
    "\n",
    "    # Constants\n",
    "    H_PLANCK = 6.626e-34  # J*s\n",
    "    C_LIGHT = 2.998e8     # m/s\n",
    "    Q_ELEM = 1.602e-19    # Coulombs\n",
    "    HC_OVER_Q = (H_PLANCK * C_LIGHT) / Q_ELEM  * 1e9 # in units of eV*nm\n",
    "\n",
    "    try:\n",
    "        wavelength = df.iloc[:2048, 5].copy() # Columns 5 is wavelength (nm) \n",
    "        spectral_irradiance = df.iloc[:2048, 6].copy() # Column 6 is spectral irradiance (W/m2/nm)\n",
    "        integral_E = np.trapezoid(spectral_irradiance, x=wavelength) # Total spectral irradiance (W/m2)\n",
    "\n",
    "        weighted_irradiance = spectral_irradiance * wavelength\n",
    "        integral_E_lambda = np.trapezoid(weighted_irradiance, x=wavelength)\n",
    "\n",
    "        ape_val = HC_OVER_Q * (integral_E / integral_E_lambda) # Average Proton Energy (APE)\n",
    "\n",
    "    except Exception as e:\n",
    "        integral_E = np.nan\n",
    "        ape_val = np.nan\n",
    "\n",
    "    ##  Irradiance measurements\n",
    "    try:\n",
    "        # Start irradiances (from row1)\n",
    "        irr_horiz_start = row1[\"irr_horiz_start\"]\n",
    "        irr_incl20_start = row1[\"irr_incl20_start\"]\n",
    "        irr_incl15_start = row1.get(\"irr_incl15_start\", np.nan)\n",
    "        irr_east_start = row1[\"irr_east_start\"]\n",
    "        irr_west_start = row1[\"irr_west_start\"]\n",
    "        irr_floor_ref_start = row1[\"irr_floor_ref_start\"]\n",
    "        irr_diffuse_start = df.iloc[0, 24] if num_cols == 26 else np.nan \n",
    "        \n",
    "        # End irradiances (from row2)\n",
    "        irr_horiz_end = row2[\"irr_horiz_end\"]\n",
    "        irr_incl20_end = row2[\"irr_incl20_end\"]\n",
    "        irr_incl15_end = row2.get(\"irr_incl15_end\", np.nan)\n",
    "        irr_east_end = row2[\"irr_east_end\"]\n",
    "        irr_west_end = row2[\"irr_west_end\"]\n",
    "        irr_floor_ref_end = row2[\"irr_floor_ref_end\"]\n",
    "        irr_diffuse_end = df.iloc[1, 24] if num_cols == 26 else np.nan\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    ## Module temperature measurements\n",
    "    try:\n",
    "        modtemp_c = row1[\"modtemp_c\"]\n",
    "        modtemp_l = row1[\"modtemp_l\"]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "    ## Electrical measurements\n",
    "    try: \n",
    "        # Get voltage, current, power columns\n",
    "        measurements = df.iloc[:, [2, 3, 4]].copy()\n",
    "        measurements.columns = ['v', 'i', 'p']\n",
    "        # Discard the first values (start from voltage close to 0)\n",
    "        min_idx = measurements['v'].idxmin()\n",
    "        measurements = measurements.iloc[min_idx:].reset_index(drop=True)\n",
    "\n",
    "        v, i = measurements['v'], measurements['i']\n",
    "        if len(v) < 10: return None # Not enough data points \n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Extract key electrical parameters\n",
    "        V_ini, I_ini = v.iloc[0], i.iloc[0] # Initial current and voltage\n",
    "        Voc_obs = v.max() # Voc\n",
    "        P = v * i # Power\n",
    "        Pmpp = P.max() # Maximum Power\n",
    "        mpp_idx = P.idxmax() # Index of MPP\n",
    "        Vmpp, Impp = v[mpp_idx], i[mpp_idx] # Values at MPP\n",
    "         \n",
    "        # Isc & Rsh (Initial Segment: V < Voc/4)\n",
    "        mask_ini = v < (Voc_obs / 6)  # Using Voc/6 to ensure we capture the linear region near Isc\n",
    "        Isc, error_Isc, Rsh = np.nan, np.nan, np.nan\n",
    "        if mask_ini.sum() >= 3:\n",
    "            # Linear regression to find Isc (intercept) and Rsh (slope)\n",
    "            vx, iy = v[mask_ini], i[mask_ini]\n",
    "            A = np.vstack([vx, np.ones_like(vx)]).T\n",
    "            m, b = np.linalg.lstsq(A, iy, rcond=None)[0]\n",
    "\n",
    "            Isc = float(b)\n",
    "            Rsh = 1 / abs(m) if abs(m) > 1e-9 else np.nan\n",
    "            # Normalized RMSE for validation\n",
    "            yhat = m * vx + b\n",
    "            rmse = np.sqrt(np.mean((iy - yhat)**2))\n",
    "            error_Isc = (rmse / Isc) if Isc > 0 else 1.0 # Normalize error as a percentage of the current signal\n",
    "\n",
    "        # Voc & Rs (Final Segment: V > 0.9 * Voc)\n",
    "        mask_fin = v > (Voc_obs * 0.9)\n",
    "        Voc_extrap, R2_Voc, Rs = np.nan, np.nan, np.nan\n",
    "        if mask_fin.sum() >= 3:\n",
    "            # Linear regression\n",
    "            vx, iy = v[mask_fin], i[mask_fin]\n",
    "            A = np.vstack([vx, np.ones_like(vx)]).T\n",
    "            m, b = np.linalg.lstsq(A, iy, rcond=None)[0]\n",
    "            # Voc is where I=0 -> 0 = mV + b -> V = -b/m\n",
    "            Voc_extrap = -b / m if abs(m) > 1e-9 else Voc_obs\n",
    "            Rs = 1 / abs(m) if abs(m) > 1e-9 else np.nan\n",
    "            # R2 Calculation\n",
    "            yhat = m*vx + b\n",
    "            ss_res = np.sum((iy - yhat)**2)\n",
    "            ss_tot = np.sum((iy - iy.mean())**2)\n",
    "            R2_Voc = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "\n",
    "        # Fill Factor\n",
    "        # Using extrapolated values if available \n",
    "        Isc_val = Isc if Isc > 0 else i.iloc[0]\n",
    "        Voc_val = Voc_extrap if Voc_extrap > 0 else Voc_obs\n",
    "        FF = Pmpp / (Isc_val * Voc_val) if (Isc_val * Voc_val) > 0 else np.nan\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "    ## Build final dataframe\n",
    "    try:\n",
    "        final_df = pd.DataFrame({\n",
    "            # Metadata\n",
    "            'filename': [filename],\n",
    "            'module_name': [module_name],\n",
    "            'timestamp': [timestamp],\n",
    "\n",
    "            # MPP\n",
    "            'Vmpp': [Vmpp],\n",
    "            'Impp': [Impp],\n",
    "            'Pmpp': [Pmpp],\n",
    "\n",
    "            # Electrical characteristics\n",
    "            'Voc': [Voc_obs],\n",
    "            'Isc': [Isc],\n",
    "            'R2_Voc': [R2_Voc],\n",
    "            'NRMSE_Isc': [error_Isc],\n",
    "            'V_ini': [V_ini],\n",
    "            'I_ini': [I_ini],\n",
    "            'FF': [FF],\n",
    "            'Rs': [Rs],\n",
    "            'Rsh': [Rsh],\n",
    "\n",
    "            # Irradiance\n",
    "            'G_spec_int': [integral_E],\n",
    "            'G_tilt20_start': [irr_incl20_start],\n",
    "            'G_tilt15_start': [irr_incl15_start],\n",
    "            'G_horiz_start': [irr_horiz_start],\n",
    "            'G_east_start': [irr_east_start],\n",
    "            'G_west_start': [irr_west_start],\n",
    "            'G_refl_start': [irr_floor_ref_start],\n",
    "            'G_diffuse_start': [irr_diffuse_start],\n",
    "\n",
    "            'G_horiz_end': [irr_horiz_end],\n",
    "            'G_tilt20_end': [irr_incl20_end],\n",
    "            'G_tilt15_end': [irr_incl15_end],\n",
    "            'G_east_end': [irr_east_end],\n",
    "            'G_west_end': [irr_west_end],\n",
    "            'G_refl_end': [irr_floor_ref_end],\n",
    "            'G_diffuse_end': [irr_diffuse_end],\n",
    "\n",
    "            # Spectral characteristics\n",
    "            'APE': [ape_val],\n",
    "\n",
    "            # Environmental characteristics\n",
    "            'module_temperature_center': [modtemp_c],\n",
    "            'module_temperature_lateral': [modtemp_l],\n",
    "            'air_temperature': [row1['airtemp']],\n",
    "            'relative_humidity': [row1['humidity_rel']],\n",
    "            'air_density': [row1['air_density']],\n",
    "            'abs_pressure': [row1['pressure_abs']],\n",
    "            'wind_speed_ms': [row1['wind_speed_ms']],\n",
    "            'wind_direction': [row1['wind_dir']]\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99848127",
   "metadata": {},
   "source": [
    "# Process Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18b12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_count = 0\n",
    "skipped_due_to_error = 0\n",
    "start_time = time.time()\n",
    "\n",
    "with open(output_csv, 'a', newline='', encoding='utf-8') as output_f:\n",
    "    for i, file_path in enumerate(all_files):  \n",
    "        filename = file_path.name  \n",
    "        \n",
    "        try:\n",
    "            result_df = process_file(file_path)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        if result_df is None:\n",
    "            continue\n",
    "\n",
    "        result_df.to_csv(output_f, header=write_header, index=False)\n",
    "        write_header = False # Update header flag after first write\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nâœ… Extraction complete. Dataset saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
